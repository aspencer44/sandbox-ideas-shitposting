{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping one page of bball ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://medium.com/analytics-vidhya/intro-to-scraping-basketball-reference-data-8adcaa79664a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning problem outline:\n",
    "\n",
    "Use the following dataset: https://www.basketball-reference.com/playoffs/series.html\n",
    "\n",
    "X = feature variables\n",
    "* odds1\n",
    "* odds2\n",
    "\n",
    "(possible intermediate step)\n",
    "* calculate implied probabilites for odds1\n",
    "* calculate implied probabilites for odds2\n",
    "\n",
    "Y = target variable\n",
    "* result (binary Y/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url we choose to scrape\n",
    "url = 'https://www.basketball-reference.com/playoffs/series.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect html data\n",
    "html = urlopen(url)\n",
    "# create BeautifulSoup object ???\n",
    "soup = BeautifulSoup(html,\n",
    "                    features = 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following somehow extracts the header columns:\n",
    "\n",
    "NB: I have 0 clue how this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yr', 'Lg', 'Series', '\\xa0', '\\xa0', 'Team', 'W', '\\xa0', 'Team', 'W', '\\xa0', 'Favorite', 'Underdog']\n"
     ]
    }
   ],
   "source": [
    "header_list = [th.getText() for th in soup.findAll('tr',limit=2)[1].findAll('th')]\n",
    "# th = tableheader\n",
    "# tr = tablerow\n",
    "print(header_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following extracts the rows\n",
    "- we have 987 total playoff series\n",
    "- filter out ones we don't have odds for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "987\n",
      "['NBA', 'Eastern Conf First Round', 'May 22 - May 29, 2021', '', 'Milwaukee Bucks (3)', '4', '', 'Miami Heat (6)', '0', '', 'MIL (-320)', 'MIA (+250)']\n"
     ]
    }
   ],
   "source": [
    "rows = soup.findAll('tr')[2:]\n",
    "rows_data = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
    "# td = tabledata\n",
    "print(len(rows_data))\n",
    "print(rows_data[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
